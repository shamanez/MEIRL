{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEIRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with initialization\n",
    "area = \"london\"\n",
    "filename = \"data/\" + area + \"/adjacency_matrix.csv\"\n",
    "adjacency_matrix = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_feature_count = adjacency_matrix.copy()\n",
    "expert_feature_count[\"value\"] = 0\n",
    "expert_feature_count = expert_feature_count[\"value\"]\n",
    "expert_feature_count = expert_feature_count.to_frame()\n",
    "learner_feature_count = expert_feature_count.copy()\n",
    "test_feature_count = expert_feature_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "all_data = 400\n",
    "training_number = int(all_data * 0.75)\n",
    "test_number = int(all_data * 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import expert trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (1,training_number):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(expert_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        expert_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "expert_feature_count = (expert_feature_count - expert_feature_count.min()) / expert_feature_count.max() - expert_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (training_number + 1 , all_data):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(test_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        test_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "test_feature_count = (test_feature_count - test_feature_count.min()) / test_feature_count.max() - test_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization of reward parameter\n",
    "reward_parameter = expert_feature_count.copy()\n",
    "reward_parameter.columns = [\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_position(current_position, eps, reward):\n",
    "    action_list = np.array(adjacency_matrix[adjacency_matrix[current_position] == 1].index)\n",
    "    value_list = reward[reward.index.isin(action_list)]\n",
    "\n",
    "    if np.random.random() > eps:\n",
    "        updated_position = random.choice(value_list[value_list[\"value\"] == max(value_list[\"value\"])].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "    else:\n",
    "        updated_position = random.choice(value_list[\"value\"].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "\n",
    "    return updated_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 283.438914027\n",
      "0.225480063301\n",
      "1 87.7196511354\n",
      "0.431096863648\n",
      "2 94.4230769231\n",
      "0.407056450298\n",
      "3 100.977060818\n",
      "0.318555249424\n",
      "4 99.5201773882\n",
      "0.355441407296\n",
      "5 101.291916795\n",
      "0.38454137405\n",
      "6 102.715047329\n",
      "0.301032697229\n",
      "7 104.403992303\n",
      "0.346947707529\n",
      "8 103.191790273\n",
      "0.305081757985\n",
      "9 100.444438807\n",
      "0.370681218432\n",
      "10 105.307660416\n",
      "0.320881387862\n",
      "11 101.210409556\n",
      "0.427311278231\n",
      "12 105.144186106\n",
      "0.336466891715\n",
      "13 103.562911541\n",
      "0.336022409116\n",
      "14 99.1859715429\n",
      "0.40439643029\n",
      "15 102.758192651\n",
      "0.340970541156\n",
      "16 102.525679994\n",
      "0.381558614379\n",
      "17 100.832026978\n",
      "0.378105219789\n",
      "18 99.8124386252\n",
      "0.384282935269\n",
      "19 102.979356921\n",
      "0.356504978766\n",
      "20 103.367461895\n",
      "0.37468004924\n",
      "21 102.90962218\n",
      "0.329337261259\n",
      "22 106.05264402\n",
      "0.398443637092\n",
      "23 103.473863452\n",
      "0.300140670805\n",
      "24 106.850735471\n",
      "0.34279356762\n",
      "25 105.144337213\n",
      "0.309545523242\n",
      "26 105.049450549\n",
      "0.325865547721\n",
      "27 103.196936361\n",
      "0.335262131194\n",
      "28 108.466924458\n",
      "0.375835815986\n",
      "29 104.419394435\n",
      "0.33469929999\n",
      "30 106.224543615\n",
      "0.284782949525\n",
      "31 104.571265715\n",
      "0.312451404259\n",
      "32 102.50739645\n",
      "0.342187644339\n",
      "33 103.890877616\n",
      "0.311057961588\n",
      "34 104.10029785\n",
      "0.30328562117\n",
      "35 104.888678223\n",
      "0.327962537485\n",
      "36 108.133061383\n",
      "0.28860939401\n",
      "37 102.566118116\n",
      "0.330798207145\n",
      "38 104.744820852\n",
      "0.321324862295\n",
      "39 102.185897436\n",
      "0.348456148709\n",
      "40 103.05586242\n",
      "0.324822934464\n",
      "41 106.944010417\n",
      "0.322941851622\n",
      "42 105.303235782\n",
      "0.281489156932\n",
      "43 102.743044963\n",
      "0.329598996027\n",
      "44 104.416710723\n",
      "0.319838538894\n",
      "45 102.936214564\n",
      "0.368620375024\n",
      "46 109.800029731\n",
      "0.272585678003\n",
      "47 105.858768839\n",
      "0.284021205028\n",
      "48 104.492342165\n",
      "0.314527156144\n",
      "49 102.123155062\n",
      "0.358395580721\n"
     ]
    }
   ],
   "source": [
    "# how many iterations?\n",
    "Y = []\n",
    "iteration = 50\n",
    "for i in range (iteration):\n",
    "    epsilon = 1 / (i+1)  \n",
    "    learner_feature_count[\"value\"] = 0\n",
    "    for j in range (1,training_number):\n",
    "        start_position = random.choice(adjacency_matrix.columns)\n",
    "        current_position = start_position\n",
    "        # agent will walk for 50 steps\n",
    "        for k in range(150):\n",
    "            current_position = str(update_position(current_position, epsilon, reward_parameter))\n",
    "            learner_feature_count.loc[int(current_position), [\"value\"]] += 1\n",
    "    \n",
    "    learner_feature_count = (learner_feature_count - learner_feature_count.min()) / (learner_feature_count.max() - learner_feature_count.min() )   \n",
    "    gradient = (expert_feature_count - learner_feature_count) \n",
    "    reward_parameter = (gradient*0.2) + reward_parameter\n",
    "    reward_parameter = (reward_parameter - reward_parameter.min()) / (reward_parameter.max() - reward_parameter.min() )   \n",
    "    \n",
    "    difference = gradient.abs().sum().values[0]\n",
    "    Y.append(difference)\n",
    "    print(i, difference)\n",
    "    \n",
    "    correlation_dataframe = pd.concat([learner_feature_count, test_feature_count], axis=1)\n",
    "    correlation = correlation_dataframe.corr().values[0][1]\n",
    "    print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local depth\n",
    "filename = \"data/\" + area + \"/\" + \"closeness_centrality.csv\"\n",
    "\n",
    "closeness_centrality = pd.read_csv(filename, index_col=0)\n",
    "adjacent_node = adjacency_matrix.sum().to_frame()\n",
    "adjacent_node.columns = [\"closeness_centrality\"]\n",
    "adjacent_node.index = adjacent_node.index.map(int)\n",
    "mean_depth = (closeness_centrality - adjacent_node) / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_local_depth = - correlation_dataframe.corr().values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406804231592879"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_local_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32460389310488996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = adjacent_node / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_connectivity = correlation_dataframe.corr().values[0][1]\n",
    "correlation_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406704994670616"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = closeness_centrality / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_global_depth = - correlation_dataframe.corr().values[0][1]\n",
    "correlation_global_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

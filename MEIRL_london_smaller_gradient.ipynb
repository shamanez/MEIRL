{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEIRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "area = \"london\"\n",
    "filename = \"data/\" + area + \"/adjacency_matrix.csv\"\n",
    "adjacency_matrix = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_feature_count = adjacency_matrix.copy()\n",
    "expert_feature_count[\"value\"] = 0\n",
    "expert_feature_count = expert_feature_count[\"value\"]\n",
    "expert_feature_count = expert_feature_count.to_frame()\n",
    "learner_feature_count = expert_feature_count.copy()\n",
    "test_feature_count = expert_feature_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "all_data = 400\n",
    "training_number = int(all_data * 0.75)\n",
    "test_number = int(all_data * 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import expert trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (1,training_number):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(expert_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        expert_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "expert_feature_count = (expert_feature_count - expert_feature_count.min()) / expert_feature_count.max() - expert_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (training_number + 1 , all_data):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(test_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        test_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "test_feature_count = (test_feature_count - test_feature_count.min()) / test_feature_count.max() - test_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization of reward parameter\n",
    "reward_parameter = expert_feature_count.copy()\n",
    "reward_parameter.columns = [\"value\"]\n",
    "reward_parameter[\"value\"] = np.random.random_sample(reward_parameter.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_position(current_position, eps, reward):\n",
    "    action_list = np.array(adjacency_matrix[adjacency_matrix[current_position] == 1].index)\n",
    "    value_list = reward[reward.index.isin(action_list)]\n",
    "\n",
    "    if np.random.random() > eps:\n",
    "        updated_position = random.choice(value_list[value_list[\"value\"] == max(value_list[\"value\"])].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "    else:\n",
    "        updated_position = random.choice(value_list[\"value\"].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "\n",
    "    return updated_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 185.480769231\n",
      "0.0885112102767\n",
      "1 144.507548526\n",
      "0.0476499807502\n",
      "2 137.463399504\n",
      "0.0937301005695\n",
      "3 136.681396618\n",
      "0.0425195514553\n",
      "4 130.820186183\n",
      "0.0619504562842\n",
      "5 135.375624376\n",
      "0.129978741136\n",
      "6 139.326923077\n",
      "0.0751393503015\n",
      "7 146.115244245\n",
      "0.0751673063498\n",
      "8 155.745622264\n",
      "0.0688316245962\n",
      "9 141.336406744\n",
      "0.129062512701\n",
      "10 137.486538462\n",
      "0.103758372286\n",
      "11 147.894844517\n",
      "0.0886570608881\n",
      "12 125.548617113\n",
      "0.156974323903\n",
      "13 146.34508547\n",
      "0.0793909646534\n",
      "14 144.429487179\n",
      "0.0787297431914\n",
      "15 158.373538462\n",
      "0.0584569958859\n",
      "16 150.951309329\n",
      "0.122459771939\n",
      "17 148.580769231\n",
      "0.196889802353\n",
      "18 158.574175824\n",
      "0.150184122709\n",
      "19 140.371794872\n",
      "0.16259885093\n",
      "20 135.758144796\n",
      "0.142340685415\n",
      "21 127.325123707\n",
      "0.218857424057\n",
      "22 119.708842559\n",
      "0.215649085109\n",
      "23 124.996540497\n",
      "0.252379028363\n",
      "24 135.287962038\n",
      "0.240338032097\n",
      "25 110.525859806\n",
      "0.260547724862\n",
      "26 134.26486014\n",
      "0.169130110037\n",
      "27 114.290309036\n",
      "0.282767194296\n",
      "28 114.932692308\n",
      "0.19433359911\n",
      "29 107.865384615\n",
      "0.261540592486\n",
      "30 114.446348399\n",
      "0.230869282981\n",
      "31 110.604483097\n",
      "0.177521585485\n",
      "32 129.995998221\n",
      "0.29014814098\n",
      "33 104.606477733\n",
      "0.221353034329\n",
      "34 119.384339345\n",
      "0.249015923976\n",
      "35 128.728571429\n",
      "0.271168862337\n",
      "36 107.887112887\n",
      "0.264785304259\n",
      "37 104.232285233\n",
      "0.251141461191\n",
      "38 103.455734266\n",
      "0.243542366676\n",
      "39 106.375031118\n",
      "0.2893403197\n",
      "40 102.909253689\n",
      "0.273671678443\n",
      "41 106.705286973\n",
      "0.295509211498\n",
      "42 108.421282051\n",
      "0.299690009328\n",
      "43 105.746665873\n",
      "0.308211167695\n",
      "44 101.504391278\n",
      "0.24315115827\n",
      "45 105.653079479\n",
      "0.351335819846\n",
      "46 109.775847143\n",
      "0.267646590604\n",
      "47 102.427552784\n",
      "0.224127062693\n",
      "48 102.209290709\n",
      "0.289511628518\n",
      "49 102.803801257\n",
      "0.30871002009\n"
     ]
    }
   ],
   "source": [
    "# how many iterations?\n",
    "Y = []\n",
    "iteration = 50\n",
    "for i in range (iteration):\n",
    "    epsilon = 1 / (i+1)  \n",
    "    learner_feature_count[\"value\"] = 0\n",
    "    for j in range (1,training_number):\n",
    "        start_position = random.choice(adjacency_matrix.columns)\n",
    "        current_position = start_position\n",
    "        # agent will walk for 50 steps\n",
    "        for k in range(50):\n",
    "            current_position = str(update_position(current_position, epsilon, reward_parameter))\n",
    "            learner_feature_count.loc[int(current_position), [\"value\"]] += 1\n",
    "    \n",
    "    learner_feature_count = (learner_feature_count - learner_feature_count.min()) / (learner_feature_count.max() - learner_feature_count.min() )   \n",
    "    gradient = (expert_feature_count - learner_feature_count) \n",
    "    reward_parameter = (gradient*0.05) + reward_parameter\n",
    "    reward_parameter = (reward_parameter - reward_parameter.min()) / (reward_parameter.max() - reward_parameter.min() )   \n",
    "    \n",
    "    difference = gradient.abs().sum().values[0]\n",
    "    Y.append(difference)\n",
    "    print(i, difference)\n",
    "    \n",
    "    correlation_dataframe = pd.concat([learner_feature_count, test_feature_count], axis=1)\n",
    "    correlation = correlation_dataframe.corr().values[0][1]\n",
    "    print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local depth\n",
    "filename = \"data/\" + area + \"/\" + \"closeness_centrality.csv\"\n",
    "\n",
    "closeness_centrality = pd.read_csv(filename, index_col=0)\n",
    "adjacent_node = adjacency_matrix.sum().to_frame()\n",
    "adjacent_node.columns = [\"closeness_centrality\"]\n",
    "adjacent_node.index = adjacent_node.index.map(int)\n",
    "mean_depth = (closeness_centrality - adjacent_node) / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_local_depth = - correlation_dataframe.corr().values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406804231592879"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_local_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32460389310488996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = adjacent_node / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_connectivity = correlation_dataframe.corr().values[0][1]\n",
    "correlation_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406704994670616"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = closeness_centrality / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_global_depth = - correlation_dataframe.corr().values[0][1]\n",
    "correlation_global_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

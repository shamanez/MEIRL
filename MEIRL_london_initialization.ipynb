{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEIRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with initialization\n",
    "area = \"london\"\n",
    "filename = \"data/\" + area + \"/adjacency_matrix.csv\"\n",
    "adjacency_matrix = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_feature_count = adjacency_matrix.copy()\n",
    "expert_feature_count[\"value\"] = 0\n",
    "expert_feature_count = expert_feature_count[\"value\"]\n",
    "expert_feature_count = expert_feature_count.to_frame()\n",
    "learner_feature_count = expert_feature_count.copy()\n",
    "test_feature_count = expert_feature_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "all_data = 400\n",
    "training_number = int(all_data * 0.75)\n",
    "test_number = int(all_data * 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import expert trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (1,training_number):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(expert_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        expert_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "expert_feature_count = (expert_feature_count - expert_feature_count.min()) / expert_feature_count.max() - expert_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (training_number + 1 , all_data):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(test_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        test_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "test_feature_count = (test_feature_count - test_feature_count.min()) / test_feature_count.max() - test_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization of reward parameter\n",
    "reward_parameter = expert_feature_count.copy()\n",
    "reward_parameter.columns = [\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_position(current_position, eps, reward):\n",
    "    action_list = np.array(adjacency_matrix[adjacency_matrix[current_position] == 1].index)\n",
    "    value_list = reward[reward.index.isin(action_list)]\n",
    "\n",
    "    if np.random.random() > eps:\n",
    "        updated_position = random.choice(value_list[value_list[\"value\"] == max(value_list[\"value\"])].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "    else:\n",
    "        updated_position = random.choice(value_list[\"value\"].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "\n",
    "    return updated_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 232.442307692\n",
      "0.0926141131824\n",
      "1 88.1923076923\n",
      "0.362064619543\n",
      "2 97.5451864087\n",
      "0.289706507719\n",
      "3 98.664523174\n",
      "0.356930858992\n",
      "4 97.4156358717\n",
      "0.343233092567\n",
      "5 101.017711012\n",
      "0.32839261463\n",
      "6 104.047986496\n",
      "0.341560352161\n",
      "7 102.507338638\n",
      "0.282476420892\n",
      "8 101.101449275\n",
      "0.282624161485\n",
      "9 100.161759882\n",
      "0.351331302742\n",
      "10 102.452471104\n",
      "0.393731124509\n",
      "11 102.68443603\n",
      "0.346305190372\n",
      "12 102.846278452\n",
      "0.341422344209\n",
      "13 101.432496075\n",
      "0.361507773374\n",
      "14 101.885869565\n",
      "0.278280104358\n",
      "15 98.7677895875\n",
      "0.376135875351\n",
      "16 100.417373501\n",
      "0.311743387534\n",
      "17 104.744917873\n",
      "0.27973853033\n",
      "18 104.658952397\n",
      "0.344899116919\n",
      "19 104.102459871\n",
      "0.353409409919\n",
      "20 102.582702816\n",
      "0.350761520569\n",
      "21 102.321694435\n",
      "0.339620353668\n",
      "22 105.900381603\n",
      "0.308243936562\n",
      "23 108.296425796\n",
      "0.259294028256\n",
      "24 106.514738911\n",
      "0.275397531388\n",
      "25 104.94585193\n",
      "0.252965791533\n",
      "26 110.789431637\n",
      "0.292192071749\n",
      "27 105.570942017\n",
      "0.247722273342\n",
      "28 103.442437338\n",
      "0.324670413888\n",
      "29 102.917395105\n",
      "0.317290218977\n",
      "30 105.069075543\n",
      "0.300950422982\n",
      "31 102.419546436\n",
      "0.359625140084\n",
      "32 111.656153846\n",
      "0.301682316785\n",
      "33 105.690934066\n",
      "0.320096351065\n",
      "34 105.303228022\n",
      "0.319635676481\n",
      "35 107.329248922\n",
      "0.347973229516\n",
      "36 103.839598725\n",
      "0.289357245045\n",
      "37 106.433499041\n",
      "0.308802027931\n",
      "38 107.384519709\n",
      "0.339030137832\n",
      "39 102.589157509\n",
      "0.334858033807\n",
      "40 106.90994695\n",
      "0.272670242808\n",
      "41 104.608791209\n",
      "0.319575908139\n",
      "42 102.495300519\n",
      "0.354407531082\n",
      "43 103.878925184\n",
      "0.332989961734\n",
      "44 108.493445151\n",
      "0.275091008929\n",
      "45 108.612012205\n",
      "0.257817381838\n",
      "46 106.114308441\n",
      "0.297677127859\n",
      "47 102.138613179\n",
      "0.367061151901\n",
      "48 108.9048583\n",
      "0.287466612354\n",
      "49 107.39479638\n",
      "0.23629981154\n"
     ]
    }
   ],
   "source": [
    "# how many iterations?\n",
    "Y = []\n",
    "iteration = 50\n",
    "for i in range (iteration):\n",
    "    epsilon = 1 / (i+1)  \n",
    "    learner_feature_count[\"value\"] = 0\n",
    "    for j in range (1,training_number):\n",
    "        start_position = random.choice(adjacency_matrix.columns)\n",
    "        current_position = start_position\n",
    "        # agent will walk for 50 steps\n",
    "        for k in range(50):\n",
    "            current_position = str(update_position(current_position, epsilon, reward_parameter))\n",
    "            learner_feature_count.loc[int(current_position), [\"value\"]] += 1\n",
    "    \n",
    "    learner_feature_count = (learner_feature_count - learner_feature_count.min()) / (learner_feature_count.max() - learner_feature_count.min() )   \n",
    "    gradient = (expert_feature_count - learner_feature_count) \n",
    "    reward_parameter = (gradient*0.2) + reward_parameter\n",
    "    reward_parameter = (reward_parameter - reward_parameter.min()) / (reward_parameter.max() - reward_parameter.min() )   \n",
    "    \n",
    "    difference = gradient.abs().sum().values[0]\n",
    "    Y.append(difference)\n",
    "    print(i, difference)\n",
    "    \n",
    "    correlation_dataframe = pd.concat([learner_feature_count, test_feature_count], axis=1)\n",
    "    correlation = correlation_dataframe.corr().values[0][1]\n",
    "    print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local depth\n",
    "filename = \"data/\" + area + \"/\" + \"closeness_centrality.csv\"\n",
    "\n",
    "closeness_centrality = pd.read_csv(filename, index_col=0)\n",
    "adjacent_node = adjacency_matrix.sum().to_frame()\n",
    "adjacent_node.columns = [\"closeness_centrality\"]\n",
    "adjacent_node.index = adjacent_node.index.map(int)\n",
    "mean_depth = (closeness_centrality - adjacent_node) / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_local_depth = - correlation_dataframe.corr().values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406804231592879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_local_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32460389310488996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = adjacent_node / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_connectivity = correlation_dataframe.corr().values[0][1]\n",
    "correlation_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406704994670616"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = closeness_centrality / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_global_depth = - correlation_dataframe.corr().values[0][1]\n",
    "correlation_global_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

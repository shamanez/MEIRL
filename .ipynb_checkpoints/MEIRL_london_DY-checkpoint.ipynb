{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEIRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "area = \"london\"\n",
    "filename = \"data/\" + area + \"/adjacency_matrix.csv\"\n",
    "adjacency_matrix = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_feature_count = adjacency_matrix.copy()\n",
    "expert_feature_count[\"value\"] = 0\n",
    "expert_feature_count = expert_feature_count[\"value\"]\n",
    "expert_feature_count = expert_feature_count.to_frame()\n",
    "learner_feature_count = expert_feature_count.copy()\n",
    "test_feature_count = expert_feature_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "all_data = 400\n",
    "training_number = int(all_data * 0.75)\n",
    "test_number = int(all_data * 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import expert trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (1,training_number):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(expert_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        expert_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "expert_feature_count = (expert_feature_count - expert_feature_count.min()) / expert_feature_count.max() - expert_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (training_number + 1 , all_data):\n",
    "    filename = \"data/\" + area + \"/\" + str(i)\n",
    "    file = open(filename, \"r\")\n",
    "    expert_trajectory = file.read().split(', ')\n",
    "    for j in expert_trajectory:\n",
    "        current_count = int(test_feature_count.loc[int(j), [\"value\"]].values[0])\n",
    "        add_count = expert_trajectory.count(j)\n",
    "        new_count = current_count + add_count \n",
    "        test_feature_count.loc[int(j), [\"value\"]] = new_count\n",
    "test_feature_count = (test_feature_count - test_feature_count.min()) / test_feature_count.max() - test_feature_count.min()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization of reward parameter\n",
    "reward_parameter = expert_feature_count.copy()\n",
    "reward_parameter.columns = [\"value\"]\n",
    "reward_parameter[\"value\"] = np.random.random_sample(reward_parameter.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_position(current_position, eps, reward):\n",
    "    action_list = np.array(adjacency_matrix[adjacency_matrix[current_position] == 1].index)\n",
    "    value_list = reward[reward.index.isin(action_list)]\n",
    "\n",
    "    if np.random.random() > eps:\n",
    "        updated_position = random.choice(value_list[value_list[\"value\"] == max(value_list[\"value\"])].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "    else:\n",
    "        updated_position = random.choice(value_list[\"value\"].index.tolist())\n",
    "#         gained_reward = value_list.loc[updated_position, \"value\"]\n",
    "\n",
    "    return updated_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = random.choice(adjacency_matrix.columns)\n",
    "current_position = start_position\n",
    "action_list = np.array(adjacency_matrix[adjacency_matrix[current_position] == 1].index)\n",
    "value_list = reward_parameter[reward_parameter.index.isin(action_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 211.074175824\n",
      "0.00156661142236\n",
      "1 123.763846154\n",
      "0.0689930166804\n",
      "2 136.624783112\n",
      "0.0733706358347\n",
      "3 146.924749164\n",
      "0.129852317794\n",
      "4 123.027657736\n",
      "0.110923593384\n",
      "5 114.713045019\n",
      "0.176343922631\n",
      "6 113.797008547\n",
      "0.218731369872\n",
      "7 150.638978668\n",
      "0.189300222634\n",
      "8 122.975937379\n",
      "0.186999523157\n",
      "9 123.686118479\n",
      "0.277891252181\n",
      "10 114.652439024\n",
      "0.272574750682\n",
      "11 107.691880342\n",
      "0.259341183384\n",
      "12 118.865734266\n",
      "0.238881458329\n",
      "13 108.562742813\n",
      "0.262748289618\n",
      "14 110.799799549\n",
      "0.286732742302\n",
      "15 105.055510907\n",
      "0.312813805943\n",
      "16 102.31636422\n",
      "0.322516131255\n",
      "17 102.871862348\n",
      "0.304463710339\n",
      "18 100.61494151\n",
      "0.413615073124\n",
      "19 103.293575339\n",
      "0.27923067469\n",
      "20 102.030062794\n",
      "0.365182796802\n",
      "21 105.782362778\n",
      "0.291824413638\n",
      "22 102.403846154\n",
      "0.31736585785\n",
      "23 103.13604612\n",
      "0.32767407473\n",
      "24 104.741933017\n",
      "0.286041988967\n",
      "25 102.008632908\n",
      "0.362185170391\n",
      "26 106.133669609\n",
      "0.348808998725\n",
      "27 103.369562641\n",
      "0.274151156707\n",
      "28 103.157833451\n",
      "0.342528642774\n",
      "29 110.70866343\n",
      "0.31469786691\n",
      "30 102.577777778\n",
      "0.301822581747\n",
      "31 106.039464883\n",
      "0.315329289096\n",
      "32 105.048857578\n",
      "0.306388308078\n",
      "33 106.243762994\n",
      "0.290765133935\n",
      "34 102.063697706\n",
      "0.310930733154\n",
      "35 103.85850881\n",
      "0.282566849747\n",
      "36 105.443724696\n",
      "0.34357912773\n",
      "37 101.930089764\n",
      "0.360081184725\n",
      "38 105.494518766\n",
      "0.321500544792\n",
      "39 105.167004049\n",
      "0.254788629979\n",
      "40 106.317610356\n",
      "0.310516219054\n",
      "41 105.24805895\n",
      "0.336912751379\n",
      "42 104.507272966\n",
      "0.320665272036\n",
      "43 104.003846154\n",
      "0.342034942345\n",
      "44 110.354305396\n",
      "0.300930807001\n",
      "45 109.404587836\n",
      "0.347330180323\n",
      "46 105.580206379\n",
      "0.296656058048\n",
      "47 105.834696499\n",
      "0.282231645189\n",
      "48 102.798925339\n",
      "0.325119317296\n",
      "49 108.533381713\n",
      "0.281123771786\n"
     ]
    }
   ],
   "source": [
    "# how many iterations?\n",
    "Y = []\n",
    "iteration = 50\n",
    "for i in range (iteration):\n",
    "    epsilon = 1 / (i+1)  \n",
    "    learner_feature_count[\"value\"] = 0\n",
    "    for j in range (1,training_number):\n",
    "        start_position = random.choice(adjacency_matrix.columns)\n",
    "        current_position = start_position\n",
    "        # agent will walk for 50 steps\n",
    "        for k in range(50):\n",
    "            current_position = str(update_position(current_position, epsilon, reward_parameter))\n",
    "            learner_feature_count.loc[int(current_position), [\"value\"]] += 1\n",
    "    \n",
    "    learner_feature_count = (learner_feature_count - learner_feature_count.min()) / (learner_feature_count.max() - learner_feature_count.min() )   \n",
    "    gradient = (expert_feature_count - learner_feature_count) \n",
    "    reward_parameter = (gradient*0.2) + reward_parameter\n",
    "    reward_parameter = (reward_parameter - reward_parameter.min()) / (reward_parameter.max() - reward_parameter.min() )   \n",
    "    \n",
    "    difference = gradient.abs().sum().values[0]\n",
    "    Y.append(difference)\n",
    "    print(i, difference)\n",
    "    \n",
    "    correlation_dataframe = pd.concat([learner_feature_count, test_feature_count], axis=1)\n",
    "    correlation = correlation_dataframe.corr().values[0][1]\n",
    "    print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local depth\n",
    "filename = \"data/\" + area + \"/\" + \"closeness_centrality.csv\"\n",
    "\n",
    "closeness_centrality = pd.read_csv(filename, index_col=0)\n",
    "adjacent_node = adjacency_matrix.sum().to_frame()\n",
    "adjacent_node.columns = [\"closeness_centrality\"]\n",
    "adjacent_node.index = adjacent_node.index.map(int)\n",
    "mean_depth = (closeness_centrality - adjacent_node) / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_local_depth = - correlation_dataframe.corr().values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406804231592879"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_local_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32460389310488996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = adjacent_node / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_connectivity = correlation_dataframe.corr().values[0][1]\n",
    "correlation_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45406704994670616"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_depth = closeness_centrality / (adjacent_node.shape[0] - 1)\n",
    "relative_asymmetry = (2*(mean_depth - 1)) / (adjacent_node.shape[0] - 2)\n",
    "relative_asymmetry = (relative_asymmetry - relative_asymmetry.min()) / (relative_asymmetry.max() - relative_asymmetry.min() )   \n",
    "correlation_dataframe = pd.concat([relative_asymmetry, test_feature_count], axis=1)\n",
    "correlation_global_depth = - correlation_dataframe.corr().values[0][1]\n",
    "correlation_global_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
